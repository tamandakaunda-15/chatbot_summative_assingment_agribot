{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamandakaunda-15/chatbot_summative_assingment_agribot/blob/main/Agribot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9qq5NenXvZb"
      },
      "source": [
        "#Data Exploration and Preprocession\n",
        "\n",
        "\n",
        "Data set used is a Malawi Secondary Ceritificate of Examination syllabus for the Agriculture subject subject, with close to 200 questions. The set of questions are a summary from over 5 MSCE syllabus books that the Ministry of Education in Malawi approved for the Agriculture subject. This chatbot will help secondary school students prepare for Agriculture examinations and increase the passing of of students taking the Agriculture subject.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEsO7ZsXo6f",
        "outputId": "66e742b7-8477-4cf9-d257-459f19d489e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.5)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install tesseract-ocr -y\n",
        "!sudo apt-get install poppler-utils -y\n",
        "%pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iN_zuBSYp9_",
        "outputId": "8d1a3725-4eaf-43ee-d6ae-1c8c4560df05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga409cU2ZnVN",
        "outputId": "28768fe5-d109-46de-a864-f99540c50738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            "Compiled by L.L Mpandason  \n",
            "1 \n",
            "MSCE AGRICULTURE \n",
            " \n",
            "QUESTIONS  \n",
            "& \n",
            " MODEL \n",
            "ANSWER \n",
            " \n",
            "MPANDASON \n",
            " \n",
            " \n",
            " \n",
            "Compiled by L.L Mpandason  \n",
            "2 \n",
            " \n",
            "LUKE LINGISON MPANDASON \n",
            "P. O Box 32 \n",
            "Phalula  \n",
            "Balaka  \n",
            "Cell: 0881 615 761/ 0995 516 420 \n",
            "Email:  lingisonluke08@gmail.com/ lukempandason@gmail.com \n",
            " \n",
            " \n",
            "Under reference from Longhorn Publishers (greymattermw.com)  \n",
            " \n",
            " \n",
            " \n",
            "©Luke L. Mpandason  \n",
            " \n",
            " \n",
            " \n",
            "All rights reserved. No part of this publication may be reproduced, stored in a retrieval system or transmitted in any \n",
            "form or by any means, electronic, mechanical, photocopying or otherwise without prior written permission of the \n",
            "copyright owner \n",
            " \n",
            " \n",
            " \n",
            "First published, 2020 \n",
            " \n",
            " \n",
            "ISBN 978 9996 038 617 \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Compiled by L.L Mpandason  \n",
            "3 \n",
            "Topics covered  \n",
            "1. Agricultural and the environment \n",
            " Soil degradation \n",
            " Agricultural and climate change \n",
            " Land drainage  \n",
            "2. Agricultural research and technology  \n",
            " Farm mechanization  \n",
            " Farm power  \n",
            " Gender and agricultural technology  \n",
            " Improved farming tec\n",
            "\n",
            "Total characters extracted: 51316\n"
          ]
        }
      ],
      "source": [
        "import fitz\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# Define the file path for your new agriculture PDF\n",
        "pdf_file_path = \"/content/drive/MyDrive/summative_assignment_chatbot/AGRICULTURE-BOOK-4-Q-A.pdf\"\n",
        "\n",
        "# Function to extract text from a digital PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    doc = fitz.open(file_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "    doc.close()\n",
        "    return full_text\n",
        "\n",
        "# Run the function to get the text\n",
        "raw_text = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "# Print a small portion of the raw text to verify the extraction\n",
        "print(raw_text[:1000])\n",
        "\n",
        "# Check the length to see if any text was extracted\n",
        "print(f\"\\nTotal characters extracted: {len(raw_text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0ySUmk2aPAK",
        "outputId": "fe128c1f-d49e-4bc1-c57b-fa81c333e63f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully parsed 161 Q&A pairs.\n",
            "\n",
            "Dataset saved to 'msce_agriculture_qa.json'.\n"
          ]
        }
      ],
      "source": [
        "def parse_agriculture_qa(text):\n",
        "    # Split the text by the question number pattern\n",
        "    chunks = re.split(r'(\\d+\\.\\s)', text)[1:]\n",
        "\n",
        "    qa_pairs = []\n",
        "\n",
        "    # Iterate through the chunks to form Q&A pairs\n",
        "    for i in range(0, len(chunks), 2):\n",
        "        question_number = chunks[i].strip()\n",
        "        content = chunks[i+1].strip()\n",
        "\n",
        "        # The answer starts on a new line or with a bullet point\n",
        "        lines = content.split('\\n', 1)\n",
        "        if len(lines) > 1:\n",
        "            question_text = lines[0].strip()\n",
        "            answer_text = lines[1].strip()\n",
        "\n",
        "            qa_pairs.append({\n",
        "                \"question\": question_text,\n",
        "                \"context\": f\"{question_text}\\n{answer_text}\",\n",
        "                \"answer\": answer_text\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Warning: Failed to parse Q&A for chunk starting with {question_number}\")\n",
        "\n",
        "    return qa_pairs\n",
        "\n",
        "# Run the parsing function on your raw text\n",
        "qa_dataset = parse_agriculture_qa(raw_text)\n",
        "\n",
        "# Save to a JSON file\n",
        "qa_df = pd.DataFrame(qa_dataset)\n",
        "qa_df.to_json('msce_agriculture_qa.json', orient='records', indent=4)\n",
        "\n",
        "print(f\"\\nSuccessfully parsed {len(qa_dataset)} Q&A pairs.\")\n",
        "print(\"\\nDataset saved to 'msce_agriculture_qa.json'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPfG9zsMayH2",
        "outputId": "fcac908e-ef26-4f04-fc64-63742c8ba472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Agricultural and the environment', 'context': 'Agricultural and the environment\\n\\uf0b7 Soil degradation \\n\\uf0b7 Agricultural and climate change \\n\\uf0b7 Land drainage', 'answer': '\\uf0b7 Soil degradation \\n\\uf0b7 Agricultural and climate change \\n\\uf0b7 Land drainage'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "# Load your structured data from the JSON file you just created\n",
        "qa_df = pd.read_json('msce_agriculture_qa.json')\n",
        "\n",
        "# Convert the pandas DataFrame to a Hugging Face Dataset object\n",
        "dataset = Dataset.from_pandas(qa_df)\n",
        "\n",
        "# Initialize the tokenizer for DistilBERT\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert/distilbert-base-cased-distilled-squad')\n",
        "\n",
        "# Display the first example to check the format\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "14374ad8935446fba77e6d88d936310e",
            "a65e06d00fb1442eb284c7ba1ee75a28",
            "c7025a133b1a409fb8eac185a7800629",
            "2fc7c186dbe94ee78777604d83827637",
            "94d392f2e3a547d7988d9dc55e919084",
            "c6ecbc2abedc436da19f5dcadba3c273",
            "6ed4a21ba82441fa97729aac9df5588e",
            "d92dce605da84d4cb0dd38775ba14aa4",
            "97cccf1edb404852959de97f80dedaf4",
            "071d714443484e2f8c6e777ce104660d",
            "9c31d87dc8fc4545810a77272cf08bd4"
          ]
        },
        "id": "SMKEGR3Va5mZ",
        "outputId": "9c8d3954-7980-405a-fe02-2a322ee645d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/161 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14374ad8935446fba77e6d88d936310e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize the questions and contexts with truncation and padding\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",  # Truncate the context if it's too long\n",
        "        max_length=512,\n",
        "        stride=128, # Add stride for overlapping chunks\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Map each tokenized example to its original example and find answer positions\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to the context and find the start and end of the context\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_sequence_index = 1 # This is typically 1 for the second sequence (context)\n",
        "\n",
        "        # Find the start and end token indices of the context\n",
        "        start_token_index = sequence_ids.index(context_sequence_index) if context_sequence_index in sequence_ids else None\n",
        "        end_token_index = len(sequence_ids) - 1\n",
        "        while end_token_index > 0 and sequence_ids[end_token_index] != context_sequence_index:\n",
        "            end_token_index -= 1\n",
        "        if end_token_index == 0 and sequence_ids[end_token_index] != context_sequence_index:\n",
        "             end_token_index = None\n",
        "\n",
        "\n",
        "        # If the answer is not in the context, set the cls_index as the answer.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answer = examples[\"answer\"][sample_index]\n",
        "        context = examples[\"context\"][sample_index]\n",
        "\n",
        "        start_char = context.find(answer)\n",
        "        end_char = start_char + len(answer)\n",
        "\n",
        "        if start_token_index is None or end_token_index is None or start_char < 0 or end_char > len(context):\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Otherwise, find the start and end token index of the answer in the context.\n",
        "            tokenized_examples[\"start_positions\"].append(start_token_index)\n",
        "            while tokenized_examples[\"start_positions\"][-1] < len(offsets) and offsets[tokenized_examples[\"start_positions\"][-1]][0] <= start_char:\n",
        "                tokenized_examples[\"start_positions\"][-1] += 1\n",
        "\n",
        "            tokenized_examples[\"end_positions\"].append(end_token_index)\n",
        "            while tokenized_examples[\"end_positions\"][-1] >= start_token_index and offsets[tokenized_examples[\"end_positions\"][-1]][1] >= end_char:\n",
        "                tokenized_examples[\"end_positions\"][-1] -= 1\n",
        "\n",
        "            # Correct the start and end indices\n",
        "            tokenized_examples[\"start_positions\"][-1] -= 1\n",
        "            tokenized_examples[\"end_positions\"][-1] += 1\n",
        "\n",
        "\n",
        "            # If the tokenized answer is out of the span limits, set the index to the CLS token\n",
        "            if not (tokenized_examples[\"start_positions\"][-1] >= start_token_index and tokenized_examples[\"end_positions\"][-1] <= end_token_index):\n",
        "                 tokenized_examples[\"start_positions\"][-1] = cls_index\n",
        "                 tokenized_examples[\"end_positions\"][-1] = cls_index\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "# Apply the function to the entire dataset\n",
        "tokenized_dataset = dataset.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=dataset.column_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xxuyj-lPA7h0"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CGIEJgmEBhwr"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "j-zS0UH7bNs9",
        "outputId": "53dd8089-7d72-4c24-e1f2-64d0d2e7daa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 296,450 || all params: 65,488,900 || trainable%: 0.4527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2214310517.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt-kaunda\u001b[0m (\u001b[33mt-kaunda-african-leadership-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251016_042247-snfm3g3p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/t-kaunda-african-leadership-university/huggingface/runs/snfm3g3p' target=\"_blank\">snowy-brook-4</a></strong> to <a href='https://wandb.ai/t-kaunda-african-leadership-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/t-kaunda-african-leadership-university/huggingface' target=\"_blank\">https://wandb.ai/t-kaunda-african-leadership-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/t-kaunda-african-leadership-university/huggingface/runs/snfm3g3p' target=\"_blank\">https://wandb.ai/t-kaunda-african-leadership-university/huggingface/runs/snfm3g3p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/168 43:26 < 30:08, 0.04 it/s, Epoch 4.71/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.516135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.201675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.925224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.694288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import DistilBertForQuestionAnswering, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained DistilBERT model\n",
        "model = DistilBertForQuestionAnswering.from_pretrained('distilbert/distilbert-base-cased-distilled-squad')\n",
        "\n",
        "# Define the PEFT (LoRA) configuration for efficient fine-tuning\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.QUESTION_ANS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"],\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./qa_model_output\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"wandb\"\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Start training!\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "trainer.save_model(\"msce_agriculture_chatbot_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8pBIlAgcLPi"
      },
      "outputs": [],
      "source": [
        "# Create a path in your Google Drive to save the model\n",
        "save_path = '/content/drive/MyDrive/summative_assignment_chatbot/msce_agriculture_chatbot_model'\n",
        "\n",
        "# Save the fine-tuned model to Google Drive\n",
        "trainer.save_model(save_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVGwDYeSQF0BCY/ZwGCY7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14374ad8935446fba77e6d88d936310e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a65e06d00fb1442eb284c7ba1ee75a28",
              "IPY_MODEL_c7025a133b1a409fb8eac185a7800629",
              "IPY_MODEL_2fc7c186dbe94ee78777604d83827637"
            ],
            "layout": "IPY_MODEL_94d392f2e3a547d7988d9dc55e919084"
          }
        },
        "a65e06d00fb1442eb284c7ba1ee75a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ecbc2abedc436da19f5dcadba3c273",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed4a21ba82441fa97729aac9df5588e",
            "value": "Map: 100%"
          }
        },
        "c7025a133b1a409fb8eac185a7800629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d92dce605da84d4cb0dd38775ba14aa4",
            "max": 161,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97cccf1edb404852959de97f80dedaf4",
            "value": 161
          }
        },
        "2fc7c186dbe94ee78777604d83827637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_071d714443484e2f8c6e777ce104660d",
            "placeholder": "​",
            "style": "IPY_MODEL_9c31d87dc8fc4545810a77272cf08bd4",
            "value": " 161/161 [00:00&lt;00:00, 602.50 examples/s]"
          }
        },
        "94d392f2e3a547d7988d9dc55e919084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ecbc2abedc436da19f5dcadba3c273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed4a21ba82441fa97729aac9df5588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d92dce605da84d4cb0dd38775ba14aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97cccf1edb404852959de97f80dedaf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "071d714443484e2f8c6e777ce104660d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c31d87dc8fc4545810a77272cf08bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}